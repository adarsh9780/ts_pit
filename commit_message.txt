fix(backend): resolve variable shadowing and schema inference issues

This commit addresses two critical bugs identified during testing:

1.  **Alert Status Update**:
    -   Fixed `TypeError: 'StatusUpdate' object is not callable` in `backend/src/ts_pit/api/routers/alerts.py`.
    -   Renamed the function argument `update` to `status_update` to prevent shadowing the imported SQLAlchemy `update` function.

2.  **Schema Inference**:
    -   Fixed `StatementError` related to SQLite Date types in `backend/scripts/generate_dummy_data.py`.
    -   Refined the logic for inferring `DATE` columns to be more specific (checking for "date" or "_at" suffix), ensuring text columns like `status` are correctly created as `TEXT` instead of `DATE`.

These changes ensure stable backend operation and correct database schema generation.

feat(agent_v3): add backend-driven multi-ticker article fetch tool

- Added backend endpoint `GET /market/news/by-ticker/{ticker}` that resolves ticker -> ISIN(s) and returns merged, de-duplicated, materiality-ranked articles.
- Added Agent v3 tool `get_articles_by_tickers` in `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/agent_v3/tools.py` to fetch one or more tickers concurrently using backend endpoint logic.
- Registered the new tool in Agent v3 `TOOL_REGISTRY` so planner/execution can select it.
- Added regression tests in `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/tests/agent_v3/test_tools_get_articles_by_tickers.py` to guard:
  - empty ticker input handling
  - multi-ticker aggregation behavior

refactor(agent_v3): remove redundant ticker news route and reuse existing alert-news backend flow

- Removed the newly introduced `/market/news/by-ticker/{ticker}` endpoint from `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/api/routers/market.py`.
- Updated `get_articles_by_tickers` in `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/agent_v3/tools.py` to use existing backend logic:
  - resolve alert IDs by ticker
  - call `get_current_alert_news_non_persisting` for those alert IDs
  - merge/dedupe/sort articles per ticker
  - execute multi-ticker fetch concurrently
- Updated regression test mocks in `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/tests/agent_v3/test_tools_get_articles_by_tickers.py` to assert behavior against the new internal alert-flow helper.

perf(agent_v3): reduce latency by forcing baseline analysis only for explicit analysis intent

- Updated baseline forcing logic in `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/agent_v3/execution.py`:
  - `analyze_current_alert` is now forced only when `intent_class` is `analyze_current_alert` or `analyze_other_alert`.
  - Removed generic "investigation/explain" fallback forcing path.
- Updated planner gating in `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/agent_v3/planning.py`:
  - forced deterministic baseline step now depends on explicit analysis intent class only.
  - direct-state shortcut no longer depends on investigation keyword heuristics.
- Narrowed deterministic intent keyword patterns in `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/agent_v3/graph.py`:
  - removed `investigate/review/explain` phrases from `ALERT_ANALYSIS_PATTERNS` to avoid auto-classifying those as analysis requests.
- Updated and added regression tests:
  - `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/tests/agent_v3/test_execution_deterministic.py`
  - `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/tests/agent_v3/test_planning_deterministic.py`
  - ensured explicit analysis still forces baseline, while investigate-text without explicit analysis intent no longer forces baseline.

fix(llm): coerce recommendation_reason to string to prevent structured output validation failures

- Updated `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/llm.py` to normalize `recommendation_reason` before schema validation.
- Added coercion rules:
  - list -> newline-joined string
  - scalar -> string
  - null -> empty string
- Applied normalization both:
  - before `ClusterSummaryOutput.model_validate(...)` for dict responses
  - before final return payload to ensure downstream consumers always receive a string
- Added regression test `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/tests/test_llm_cluster_summary.py` to lock this behavior.

perf(streaming): enable incremental token streaming in Azure LLM wrapper

- Updated `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/azure_llm.py` to implement:
  - `_stream(...)` delegating to wrapped model `_stream(...)`
  - `_astream(...)` delegating to wrapped model `_astream(...)`
- This allows LangGraph `astream_events` to emit `on_chat_model_stream` token chunks, improving perceived latency in chat UI.
- Added regression tests in `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/tests/test_azure_llm_streaming.py` to verify sync and async stream delegation.

perf(agent-stream): stream planner/validator model chunks instead of waiting for fallback updates

- Updated `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/api/routers/agent.py`:
  - `_should_stream_model_chunk(...)` now streams chunks for all user-facing fallback model nodes (via `FALLBACK_MODEL_OUTPUT_NODES`) rather than the narrower `STREAMABLE_MODEL_NODES` allowlist.
- This reduces perceived latency by showing planner/other model text as it is generated, instead of waiting for `on_chain_end` fallback emission.
- Updated regression test in `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/tests/api/test_agent_streaming.py`:
  - planner node is now expected to stream.

perf(agent_v3): collapse response quality pipeline and reduce per-step LLM selection latency

- Updated graph routing in `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/agent_v3/graph.py`:
  - removed `answer_validator` and `answer_rewriter` from active graph path
  - `respond` now terminates directly (`__end__`)
- Enhanced `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/agent_v3/responding.py`:
  - integrated deterministic quality checks directly in respond phase
  - added single in-node repair pass when deterministic issues are detected
- Extended planner schema/output in `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/agent_v3/planning.py`:
  - planner steps now support optional `tool_name` + `tool_args_json`
  - runtime steps carry planner-provided tool/args into `StepState`
- Updated planner prompt `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/agent_v3/prompts/planner.yaml`:
  - allows optional tool+args generation
  - explicitly requires schema grounding before SQL steps
- Added hard execution safety in `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/agent_v3/execution.py`:
  - if SQL is selected and schema not yet grounded, force `read_file("artifacts/DB_SCHEMA_REFERENCE.yaml")` preflight
  - uses planner-provided tool/args directly on first attempt to skip extra execution-proposal LLM call
- Updated respond prompt `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/agent_v3/prompts/respond.yaml` with `quality_hint`.

Tests:
- Updated `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/tests/agent_v3/test_execution_deterministic.py`:
  - planner-provided tool+args bypass proposal call
  - SQL schema preflight runs before execute_sql
- Updated `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/tests/agent_v3/test_planning_deterministic.py`:
  - planner tool args are propagated to runtime step state

fix(streaming): remove in-node second-pass rewrite to prevent duplicated final output chunks

- Updated `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/agent_v3/responding.py`:
  - removed the second `llm.invoke(...)` "repair" pass inside `respond_node`
  - `respond_node` now emits a single final-generation stream per turn
- This avoids draft+repair concatenation in the frontend when token streaming is enabled.

feat(observability): integrate optional Langfuse tracing for LLM calls with safe fallback behavior

- Added `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/observability.py`:
  - `get_langfuse_callbacks()` builds Langfuse callback handlers from env vars.
  - Tracing is opt-in via `LANGFUSE_ENABLED` (or auto-enabled when keys exist).
  - Missing SDK/config now degrades gracefully without breaking model calls.
- Updated `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/llm.py`:
  - wires Langfuse callbacks into both Gemini (`init_chat_model`) and Azure (`AzureOpenAIModel`) model setup.
- Updated `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/azure_llm.py`:
  - accepts optional `callbacks` and forwards them into `init_chat_model`.
- Updated `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/pyproject.toml` and `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/uv.lock`:
  - adds `langfuse` dependency.
- Updated `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/README.md`:
  - documents Langfuse env-based setup and unauth local mode option.

Tests added:
- `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/tests/test_observability_langfuse.py`
- `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/tests/test_llm_langfuse_wiring.py`

Validation run:
- `uv run --project backend pytest backend/tests/test_observability_langfuse.py backend/tests/test_llm_langfuse_wiring.py backend/tests/test_azure_llm_streaming.py backend/tests/test_llm_cluster_summary.py`

fix(observability): support Langfuse v3 callback import path so traces are emitted

- Root cause: installed Langfuse SDK exposes callback handler at `langfuse.langchain.CallbackHandler`, while implementation only attempted legacy `langfuse.callback.CallbackHandler`.
- Updated `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/observability.py`:
  - `_resolve_langfuse_handler_class()` now tries both module paths in order:
    1. `langfuse.langchain` (new)
    2. `langfuse.callback` (legacy fallback)
- Added regression tests in `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/tests/test_observability_langfuse.py`:
  - verifies new module path resolution
  - verifies fallback to legacy module path

Validation run:
- `uv run --project backend pytest backend/tests/test_observability_langfuse.py backend/tests/test_llm_langfuse_wiring.py`

fix(observability): handle Langfuse callback constructor signature differences (v3)

- Root cause: installed `langfuse.langchain.CallbackHandler` constructor does not accept `secret_key`/`host` kwargs, causing callback creation failure and zero traces.
- Updated `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/observability.py`:
  - inspects callback constructor signature and passes only supported kwargs
  - preserves all kwargs when handler accepts `**kwargs`
- Added regression test in `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/tests/test_observability_langfuse.py`:
  - `test_handler_kwargs_are_filtered_by_constructor_signature`

Validation run:
- `uv run --project backend pytest backend/tests/test_observability_langfuse.py backend/tests/test_llm_langfuse_wiring.py`

fix(observability): initialize Langfuse client before creating callback handler

- Root cause: SDK warning `No Langfuse client with public key ... has been initialized` indicates callback looked up a client that was never initialized.
- Updated `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/src/ts_pit/observability.py`:
  - added `_resolve_langfuse_client_class()` and `_initialize_langfuse_client(...)`
  - `get_langfuse_callbacks()` now initializes `Langfuse(...)` (when keys are present) before constructing callback handler.
- Added regression test in `/Users/adarshmaurya/Downloads/Projects/ts_pit/backend/tests/test_observability_langfuse.py`:
  - `test_initializes_langfuse_client_before_callback`

Validation run:
- `uv run --project backend pytest backend/tests/test_observability_langfuse.py backend/tests/test_llm_langfuse_wiring.py`
